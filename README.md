# onnxruntime-mac :
Unlocking onnxruntime to maximize computing abilities of devices on MacOS, silicon and intel.  


## Silicon
Not sure yet of what triggered the change in neural engine, but ANE is being used now with CoreML execution provider.
With CoreML on M2 and M1max, and  M1max without CoreML as reference. 
M2 mps device
![image](https://github.com/Oil3/onnxruntime-mac/assets/22565084/a4346c5c-2a8f-4501-bb1b-11b038687223)
M1max mps device
![image](https://github.com/Oil3/onnxruntime-mac/assets/22565084/a6eb5b32-82b5-4537-a71b-82096f1a02c8)
M1max, cpu device only
![image](https://github.com/Oil3/onnxruntime-mac/assets/22565084/05c71a0d-1d5a-4cfb-9f42-842bc47f8258)


## Intel x86
Available: onnxruntime with CoreML support for intel macs.  

Done: CoreML provider used  

In progress: eGPU used



![Screenshot 2023-12-14 at 4 48 25â€¯AM](https://github.com/Oil3/onnxruntime-mac/assets/22565084/e9aa631c-712c-40be-9d4b-811485155b60)


  



All licences default to their original licence if any, and if not applicable, to "The Unlicence".
